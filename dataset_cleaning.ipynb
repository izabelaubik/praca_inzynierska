{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEFevtSyL6Mb"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zbiór danych pochodzi ze strony https://nijianmo.github.io/amazon/index.html.\n",
        "\n",
        "Wykorzystano z niej również instrukcję\n",
        "odnośnie sposobu w jaki zbiór załadować w celu dalszych operacji na nim."
      ],
      "metadata": {
        "id": "jiDFOtifSRIt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbiLkTb24D29"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "import json\n",
        "import re\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield json.loads(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "df = getDF('/content/drive/MyDrive/dataset.json.gz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laa4QAlBDlLs"
      },
      "outputs": [],
      "source": [
        "dataset = df.filter(['reviewText', 'overall'])\n",
        "dataset = dataset.rename(columns={'reviewText': 'text', 'overall': 'score'})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset[dataset['score'] != 3]\n",
        "dataset['score'] = dataset['score'].apply(lambda x: 1 if x > 3 else 0)"
      ],
      "metadata": {
        "id": "0UPh5oMNi_ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHE3ynmC2iN9"
      },
      "outputs": [],
      "source": [
        "patterns = [\n",
        "  \"\\w*\\d\\w*\", #removing digits\n",
        "  r\"(http\\S+)\", #removing URLs\n",
        "  r\"([\\w\\.\\-\\_]+@[\\w\\.\\-\\_]+)\", #removing e-mails\n",
        "  r\"([^a-zA-Z\\s])\" #removing special characters\n",
        "  r\"(@[A-Za-z0-9_]+)\", #removing @pings\n",
        "  r\"(#[A-Za-z0-9_]+)\" #removing hashtags\n",
        "  r\"[\\n\\t\\s]*\"] #Remove all white \\t spaces, new lines \\n and tabs \\t\n",
        "\n",
        "for pattern in patterns:\n",
        "  dataset['text'] = dataset['text'].apply(lambda x: re.sub(pattern, '', str(x)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "dataset['text']=dataset['text'].apply(lambda x: remove_emoji(x))"
      ],
      "metadata": {
        "id": "_37pobZuU7pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rrbt5sM7S1mi"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.dropna()\n",
        "dataset = dataset.drop_duplicates(subset=['text'], keep='first')\n",
        "dataset = dataset[dataset['text'].str.len() > 0]\n",
        "dataset['text'] = dataset['text'].str.strip() #remove tabs (trailing and leading spaces)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sojl6mwtmeMU"
      },
      "outputs": [],
      "source": [
        "dataset.to_csv(open('/content/drive/MyDrive/dataset.csv', 'wb'), index=False)"
      ]
    }
  ]
}